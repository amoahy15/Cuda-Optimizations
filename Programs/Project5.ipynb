{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6jZdedVT0xC",
        "outputId": "b277ef26-8032-48fb-cdeb-8e5da358e9b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.10/dist-packages (2022.2.2)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.10/dist-packages (from pycuda) (2022.1.14)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.4.4)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.2.4)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.2)\n",
            "1 device(s) found.\n",
            "Device: %s Tesla T4\n",
            " Compute Capability: 7.5\n",
            " Total Memory: 15464256 KB\n",
            " ASYNC_ENGINE_COUNT: 3\n",
            " CAN_MAP_HOST_MEMORY: 1\n",
            " CAN_USE_HOST_POINTER_FOR_REGISTERED_MEM: 1\n",
            " CLOCK_RATE: 1590000\n",
            " COMPUTE_CAPABILITY_MAJOR: 7\n",
            " COMPUTE_CAPABILITY_MINOR: 5\n",
            " COMPUTE_MODE: DEFAULT\n",
            " COMPUTE_PREEMPTION_SUPPORTED: 1\n",
            " CONCURRENT_KERNELS: 1\n",
            " CONCURRENT_MANAGED_ACCESS: 1\n",
            " DIRECT_MANAGED_MEM_ACCESS_FROM_HOST: 0\n",
            " ECC_ENABLED: 1\n",
            " GENERIC_COMPRESSION_SUPPORTED: 0\n",
            " GLOBAL_L1_CACHE_SUPPORTED: 1\n",
            " GLOBAL_MEMORY_BUS_WIDTH: 256\n",
            " GPU_OVERLAP: 1\n",
            " HANDLE_TYPE_POSIX_FILE_DESCRIPTOR_SUPPORTED: 1\n",
            " HANDLE_TYPE_WIN32_HANDLE_SUPPORTED: 0\n",
            " HANDLE_TYPE_WIN32_KMT_HANDLE_SUPPORTED: 0\n",
            " HOST_NATIVE_ATOMIC_SUPPORTED: 0\n",
            " INTEGRATED: 0\n",
            " KERNEL_EXEC_TIMEOUT: 0\n",
            " L2_CACHE_SIZE: 4194304\n",
            " LOCAL_L1_CACHE_SUPPORTED: 1\n",
            " MANAGED_MEMORY: 1\n",
            " MAXIMUM_SURFACE1D_LAYERED_LAYERS: 2048\n",
            " MAXIMUM_SURFACE1D_LAYERED_WIDTH: 32768\n",
            " MAXIMUM_SURFACE1D_WIDTH: 32768\n",
            " MAXIMUM_SURFACE2D_HEIGHT: 65536\n",
            " MAXIMUM_SURFACE2D_LAYERED_HEIGHT: 32768\n",
            " MAXIMUM_SURFACE2D_LAYERED_LAYERS: 2048\n",
            " MAXIMUM_SURFACE2D_LAYERED_WIDTH: 32768\n",
            " MAXIMUM_SURFACE2D_WIDTH: 131072\n",
            " MAXIMUM_SURFACE3D_DEPTH: 16384\n",
            " MAXIMUM_SURFACE3D_HEIGHT: 16384\n",
            " MAXIMUM_SURFACE3D_WIDTH: 16384\n",
            " MAXIMUM_SURFACECUBEMAP_LAYERED_LAYERS: 2046\n",
            " MAXIMUM_SURFACECUBEMAP_LAYERED_WIDTH: 32768\n",
            " MAXIMUM_SURFACECUBEMAP_WIDTH: 32768\n",
            " MAXIMUM_TEXTURE1D_LAYERED_LAYERS: 2048\n",
            " MAXIMUM_TEXTURE1D_LAYERED_WIDTH: 32768\n",
            " MAXIMUM_TEXTURE1D_LINEAR_WIDTH: 268435456\n",
            " MAXIMUM_TEXTURE1D_MIPMAPPED_WIDTH: 32768\n",
            " MAXIMUM_TEXTURE1D_WIDTH: 131072\n",
            " MAXIMUM_TEXTURE2D_ARRAY_HEIGHT: 32768\n",
            " MAXIMUM_TEXTURE2D_ARRAY_NUMSLICES: 2048\n",
            " MAXIMUM_TEXTURE2D_ARRAY_WIDTH: 32768\n",
            " MAXIMUM_TEXTURE2D_GATHER_HEIGHT: 32768\n",
            " MAXIMUM_TEXTURE2D_GATHER_WIDTH: 32768\n",
            " MAXIMUM_TEXTURE2D_HEIGHT: 65536\n",
            " MAXIMUM_TEXTURE2D_LINEAR_HEIGHT: 65000\n",
            " MAXIMUM_TEXTURE2D_LINEAR_PITCH: 2097120\n",
            " MAXIMUM_TEXTURE2D_LINEAR_WIDTH: 131072\n",
            " MAXIMUM_TEXTURE2D_MIPMAPPED_HEIGHT: 32768\n",
            " MAXIMUM_TEXTURE2D_MIPMAPPED_WIDTH: 32768\n",
            " MAXIMUM_TEXTURE2D_WIDTH: 131072\n",
            " MAXIMUM_TEXTURE3D_DEPTH: 16384\n",
            " MAXIMUM_TEXTURE3D_DEPTH_ALTERNATE: 32768\n",
            " MAXIMUM_TEXTURE3D_HEIGHT: 16384\n",
            " MAXIMUM_TEXTURE3D_HEIGHT_ALTERNATE: 8192\n",
            " MAXIMUM_TEXTURE3D_WIDTH: 16384\n",
            " MAXIMUM_TEXTURE3D_WIDTH_ALTERNATE: 8192\n",
            " MAXIMUM_TEXTURECUBEMAP_LAYERED_LAYERS: 2046\n",
            " MAXIMUM_TEXTURECUBEMAP_LAYERED_WIDTH: 32768\n",
            " MAXIMUM_TEXTURECUBEMAP_WIDTH: 32768\n",
            " MAX_BLOCKS_PER_MULTIPROCESSOR: 16\n",
            " MAX_BLOCK_DIM_X: 1024\n",
            " MAX_BLOCK_DIM_Y: 1024\n",
            " MAX_BLOCK_DIM_Z: 64\n",
            " MAX_GRID_DIM_X: 2147483647\n",
            " MAX_GRID_DIM_Y: 65535\n",
            " MAX_GRID_DIM_Z: 65535\n",
            " MAX_PERSISTING_L2_CACHE_SIZE: 0\n",
            " MAX_PITCH: 2147483647\n",
            " MAX_REGISTERS_PER_BLOCK: 65536\n",
            " MAX_REGISTERS_PER_MULTIPROCESSOR: 65536\n",
            " MAX_SHARED_MEMORY_PER_BLOCK: 49152\n",
            " MAX_SHARED_MEMORY_PER_BLOCK_OPTIN: 65536\n",
            " MAX_SHARED_MEMORY_PER_MULTIPROCESSOR: 65536\n",
            " MAX_THREADS_PER_BLOCK: 1024\n",
            " MAX_THREADS_PER_MULTIPROCESSOR: 1024\n",
            " MEMORY_CLOCK_RATE: 5001000\n",
            " MEMORY_POOLS_SUPPORTED: 1\n",
            " MULTIPROCESSOR_COUNT: 40\n",
            " MULTI_GPU_BOARD: 0\n",
            " MULTI_GPU_BOARD_GROUP_ID: 0\n",
            " PAGEABLE_MEMORY_ACCESS: 0\n",
            " PAGEABLE_MEMORY_ACCESS_USES_HOST_PAGE_TABLES: 0\n",
            " PCI_BUS_ID: 0\n",
            " PCI_DEVICE_ID: 4\n",
            " PCI_DOMAIN_ID: 0\n",
            " READ_ONLY_HOST_REGISTER_SUPPORTED: 1\n",
            " RESERVED_SHARED_MEMORY_PER_BLOCK: 0\n",
            " SINGLE_TO_DOUBLE_PRECISION_PERF_RATIO: 32\n",
            " STREAM_PRIORITIES_SUPPORTED: 1\n",
            " SURFACE_ALIGNMENT: 512\n",
            " TCC_DRIVER: 0\n",
            " TEXTURE_ALIGNMENT: 512\n",
            " TEXTURE_PITCH_ALIGNMENT: 32\n",
            " TOTAL_CONSTANT_MEMORY: 65536\n",
            " UNIFIED_ADDRESSING: 1\n",
            " WARP_SIZE: 32\n"
          ]
        }
      ],
      "source": [
        "# install the pycuda library\n",
        "!pip install pycuda\n",
        "\n",
        "import pycuda.autoinit\n",
        "import pycuda.driver as cuda\n",
        "\n",
        "# check available GPUs\n",
        "print(\"%d device(s) found.\" % cuda.Device.count())\n",
        "\n",
        "# save device information\n",
        "dev = cuda.Device(0)\n",
        "print(\"Device: %s\", dev.name()) # device name\n",
        "print(\" Compute Capability: %d.%d\" % dev.compute_capability()) # device compute capability\n",
        "print(\" Total Memory: %s KB\" % (dev.total_memory()//(1024))) # device memory\n",
        "\n",
        "# all the device attributes in sorted order\n",
        "atts = [(str(att), value)\n",
        " for att, value in dev.get_attributes().items()]\n",
        "atts.sort()\n",
        " \n",
        "for att, value in atts:\n",
        " print(\" %s: %s\" % (att, value))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Matrix Multiplication Naive\n"
      ],
      "metadata": {
        "id": "duyhLaSpUBM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "import numpy as np\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "BLOCK_SIZE = 16\n",
        "\n",
        "# Define the matrix multiplication kernel\n",
        "mod = SourceModule(\"\"\"\n",
        "__global__ void matrixMult(float *A, float *B, float *C, int size)\n",
        "{\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int k;\n",
        "    if (row < size && col < size)\n",
        "    {\n",
        "        float sum = 0.0f;\n",
        "        for (k = 0; k < size; k++)\n",
        "        {\n",
        "            sum += A[row * size + k] * B[k * size + col];\n",
        "        }\n",
        "        C[row * size + col] = sum;\n",
        "    }\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "# Get the kernel function\n",
        "matrixMult = mod.get_function(\"matrixMult\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import sys\n",
        "    if len(sys.argv) != 2:\n",
        "        print(\"Usage: {} size\".format(sys.argv[0]))\n",
        "        exit(1)\n",
        "\n",
        "    size = 5\n",
        "    input_size = size * size * np.dtype(np.float32).itemsize\n",
        "    if size <= 0:\n",
        "        print(\"Invalid matrix size: {}\".format(size))\n",
        "        exit(1)\n",
        "\n",
        "    # Allocate memory for matrices A, B, and C on the host\n",
        "    A = np.random.rand(size, size).astype(np.float32)\n",
        "    B = np.random.rand(size, size).astype(np.float32)\n",
        "    C = np.zeros((size, size), dtype=np.float32)\n",
        "\n",
        "    # Allocate memory for matrices A, B, and C on the device\n",
        "    dev_a = cuda.mem_alloc(input_size)\n",
        "    dev_b = cuda.mem_alloc(input_size)\n",
        "    dev_c = cuda.mem_alloc(input_size)\n",
        "\n",
        "    # Copy matrices A and B from host to device\n",
        "    cuda.memcpy_htod(dev_a, A)\n",
        "    cuda.memcpy_htod(dev_b, B)\n",
        "\n",
        "    # Define the grid and block dimensions for the MatrixMultKernel\n",
        "    dimBlock = (BLOCK_SIZE, BLOCK_SIZE, 1)\n",
        "    dimGrid = ((size + BLOCK_SIZE - 1) // BLOCK_SIZE, (size + BLOCK_SIZE - 1) // BLOCK_SIZE)\n",
        "\n",
        "    # Create CUDA events to measure the execution time\n",
        "    start = cuda.Event()\n",
        "    stop = cuda.Event()\n",
        "\n",
        "    # Call the MatrixMultKernel on the device\n",
        "    start.record()\n",
        "    matrixMult(dev_a, dev_b, dev_c, np.int32(size), block=dimBlock, grid=dimGrid)\n",
        "    stop.record()\n",
        "    stop.synchronize()\n",
        "\n",
        "    # Copy matrix C from device to host\n",
        "    cuda.memcpy_dtoh(C, dev_c)\n",
        "\n",
        "    # Calculate the elapsed time in seconds\n",
        "    elapsedTime = stop.time_since(start)\n",
        "\n",
        "    # Print the execution time\n",
        "    print(\"Execution time: {} ms\".format(elapsedTime))\n",
        "    \n",
        "    # Free memory\n",
        "    del A, B, C\n",
        "    dev_a.free()\n",
        "    dev_b.free()\n",
        "    dev_c.free()\n",
        "  \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAYtVVQOUlLD",
        "outputId": "27177f42-97bf-4dec-d72f-20085d437748"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usage: /usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py size\n",
            "Execution time: 0.0936959981918335 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Matrix Multiplication Tiled\n"
      ],
      "metadata": {
        "id": "wmZo3BWKUJF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.autoinit\n",
        "import pycuda.driver as drv\n",
        "from pycuda.compiler import SourceModule\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "BLOCK_SIZE = 16\n",
        "\n",
        "mod = SourceModule(\"\"\"\n",
        "#define TILE_SIZE 16\n",
        "__global__ void matrixMult(float *A, float *B, float *C, int size)\n",
        "{\n",
        "    __shared__ float As[TILE_SIZE][TILE_SIZE];\n",
        "    __shared__ float Bs[TILE_SIZE][TILE_SIZE];\n",
        "\n",
        "    int bx = blockIdx.x;\n",
        "    int by = blockIdx.y;\n",
        "    int tx = threadIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "\n",
        "    int row = by * TILE_SIZE + ty;\n",
        "    int col = bx * TILE_SIZE + tx;\n",
        "\n",
        "    float sum = 0.0f;\n",
        "\n",
        "    for (int k = 0; k < size / TILE_SIZE; k++)\n",
        "    {\n",
        "        // Load tiles into shared memory\n",
        "        As[ty][tx] = A[row * size + k * TILE_SIZE + tx];\n",
        "        Bs[ty][tx] = B[(k * TILE_SIZE + ty) * size + col];\n",
        "\n",
        "        // Synchronize to ensure all tiles are loaded\n",
        "        __syncthreads();\n",
        "\n",
        "        // Multiply the tiles and accumulate the result\n",
        "        for (int i = 0; i < TILE_SIZE; i++)\n",
        "        {\n",
        "            sum += As[ty][i] * Bs[i][tx];\n",
        "        }\n",
        "\n",
        "        // Synchronize to ensure all tiles are used before overwriting shared memory\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Write the result to the output matrix\n",
        "    if (row < size && col < size)\n",
        "    {\n",
        "        C[row * size + col] = sum;\n",
        "    }\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "matrixMult = mod.get_function(\"matrixMult\")\n",
        "\n",
        "def main(size):\n",
        "\n",
        "    input_size = size * size * np.dtype(np.float32).itemsize\n",
        "\n",
        "    if size <= 0:\n",
        "        print(\"Invalid matrix size: \", size)\n",
        "        return\n",
        "\n",
        "    # Allocate memory for matrices A, B, and C on the host\n",
        "    A = np.random.rand(size, size).astype(np.float32)\n",
        "    B = np.random.rand(size, size).astype(np.float32)\n",
        "    C = np.empty_like(A)\n",
        "\n",
        "    # Allocate memory for matrices A, B, and C on the device\n",
        "    dev_a = drv.mem_alloc(input_size)\n",
        "    dev_b = drv.mem_alloc(input_size)\n",
        "    dev_c = drv.mem_alloc(input_size)\n",
        "\n",
        "       # Copy matrices A and B from host to device\n",
        "    drv.memcpy_htod(dev_a, A)\n",
        "    drv.memcpy_htod(dev_b, B)\n",
        "\n",
        "    # Define the grid and block dimensions for the MatrixMultKernel\n",
        "    dimBlock = (BLOCK_SIZE, BLOCK_SIZE, 1)\n",
        "    dimGrid = ((size + BLOCK_SIZE - 1) // BLOCK_SIZE, (size + BLOCK_SIZE - 1) // BLOCK_SIZE, 1)\n",
        "\n",
        "    # Create CUDA events to measure the execution time\n",
        "    start = drv.Event()\n",
        "    stop = drv.Event()\n",
        "\n",
        "    # Call the MatrixMultKernel on the device\n",
        "    start.record()\n",
        "    matrixMult(dev_a, dev_b, dev_c, np.int32(size), block=dimBlock, grid=dimGrid)\n",
        "    stop.record()\n",
        "    stop.synchronize()\n",
        "\n",
        "    # Copy matrix C from device to host\n",
        "    drv.memcpy_dtoh(C, dev_c)\n",
        "\n",
        "    # Calculate the elapsed time in milliseconds\n",
        "    elapsed_time = stop.time_since(start)\n",
        "\n",
        "    # Print the execution time\n",
        "    print(\"Execution time: {:.3f} ms\".format(elapsed_time))\n",
        "\n",
        "  \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main(5)\n"
      ],
      "metadata": {
        "id": "zLC2y7N6VKeT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f46d49d-0e95-467e-be71-0a503aeb5ff8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 0.119 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Matrix Multiplication Atomics\n"
      ],
      "metadata": {
        "id": "-GA4tCdwUMbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.autoinit\n",
        "import pycuda.driver as drv\n",
        "from pycuda.compiler import SourceModule\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "BLOCK_SIZE = 16\n",
        "\n",
        "mod = SourceModule(\"\"\"\n",
        "    #define BLOCK_SIZE 16\n",
        "    __global__ void matrixMult(float *A, float *B, float *C, int size) {\n",
        "        __shared__ float tileA[BLOCK_SIZE][BLOCK_SIZE];\n",
        "        __shared__ float tileB[BLOCK_SIZE][BLOCK_SIZE];\n",
        "\n",
        "        int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "        int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "        float sum = 0.0f;\n",
        "\n",
        "        for (int t = 0; t < (size + BLOCK_SIZE - 1) / BLOCK_SIZE; t++) {\n",
        "            int tiledRow = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "            int tiledCol = t * blockDim.x + threadIdx.x;\n",
        "\n",
        "            if (tiledRow < size && tiledCol < size)\n",
        "                tileA[threadIdx.y][threadIdx.x] = A[tiledRow * size + tiledCol];\n",
        "            else\n",
        "                tileA[threadIdx.y][threadIdx.x] = 0.0;\n",
        "\n",
        "            tiledRow = t * blockDim.y + threadIdx.y;\n",
        "            tiledCol = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "            if (tiledRow < size && tiledCol < size)\n",
        "                tileB[threadIdx.y][threadIdx.x] = B[tiledRow * size + tiledCol];\n",
        "            else\n",
        "                tileB[threadIdx.y][threadIdx.x] = 0.0;\n",
        "\n",
        "            __syncthreads();\n",
        "\n",
        "            for (int i = 0; i < BLOCK_SIZE; i++) {\n",
        "                sum += tileA[threadIdx.y][i] * tileB[i][threadIdx.x];\n",
        "            }\n",
        "\n",
        "            __syncthreads();\n",
        "        }\n",
        "\n",
        "        if (row < size && col < size)\n",
        "            atomicAdd(&C[row * size + col], sum);\n",
        "    }\n",
        "    \"\"\")\n",
        "\n",
        "matrixMult = mod.get_function(\"matrixMult\")\n",
        "\n",
        "def main(size):\n",
        "\n",
        "    input_size = size * size * np.dtype(np.float32).itemsize\n",
        "\n",
        "    if size <= 0:\n",
        "        print(\"Invalid matrix size: \", size)\n",
        "        return\n",
        "\n",
        "    # Allocate memory for matrices A, B, and C on the host\n",
        "    A = np.random.rand(size, size).astype(np.float32)\n",
        "    B = np.random.rand(size, size).astype(np.float32)\n",
        "    C = np.empty_like(A)\n",
        "\n",
        "    # Allocate memory for matrices A, B, and C on the device\n",
        "    dev_a = drv.mem_alloc(input_size)\n",
        "    dev_b = drv.mem_alloc(input_size)\n",
        "    dev_c = drv.mem_alloc(input_size)\n",
        "\n",
        "       # Copy matrices A and B from host to device\n",
        "    drv.memcpy_htod(dev_a, A)\n",
        "    drv.memcpy_htod(dev_b, B)\n",
        "\n",
        "    # Define the grid and block dimensions for the MatrixMultKernel\n",
        "    dimBlock = (BLOCK_SIZE, BLOCK_SIZE, 1)\n",
        "    dimGrid = ((size + BLOCK_SIZE - 1) // BLOCK_SIZE, (size + BLOCK_SIZE - 1) // BLOCK_SIZE, 1)\n",
        "\n",
        "    # Create CUDA events to measure the execution time\n",
        "    start = drv.Event()\n",
        "    stop = drv.Event()\n",
        "\n",
        "    # Call the MatrixMultKernel on the device\n",
        "    start.record()\n",
        "    matrixMult(dev_a, dev_b, dev_c, np.int32(size), block=dimBlock, grid=dimGrid)\n",
        "    stop.record()\n",
        "    stop.synchronize()\n",
        "\n",
        "    # Copy matrix C from device to host\n",
        "    drv.memcpy_dtoh(C, dev_c)\n",
        "\n",
        "    # Calculate the elapsed time in milliseconds\n",
        "    elapsed_time = stop.time_since(start)\n",
        "\n",
        "    # Print the execution time\n",
        "    print(\"Execution time: {:.3f} ms\".format(elapsed_time))\n",
        "\n",
        "  \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main(5)\n"
      ],
      "metadata": {
        "id": "jZHwKJmIa0Vw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06c19476-1e20-42b3-a71d-27a02cf53e33"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 0.109 ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/google/colab/_variable_inspector.py:27: UserWarning: module in out-of-thread context could not be cleaned up\n",
            "  globals().clear()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ke_E5T2EhUvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fC5UUQvCUGuH"
      }
    }
  ]
}